{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras import Sequential, Model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "import copy\n",
    "\n",
    "import Environment as E\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "\n",
    "n_agents = 1\n",
    "\n",
    "# Model\n",
    "\n",
    "time_steps = 3\n",
    "grid_size_w = 5\n",
    "grid_size_h = 5\n",
    "n_actions = 5\n",
    "\n",
    "n_channels = time_steps + time_steps + 1\n",
    "\n",
    "# Q-Learning\n",
    "\n",
    "n_episodes = 10\n",
    "n_steps = 1000000\n",
    "epsilon = 0.75\n",
    "epsilon_decay = 0.99\n",
    "gamma = 0.9\n",
    "\n",
    "# Policy Gradient\n",
    "\n",
    "n_runs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3, 5, 5)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 4, 4)          208       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 3, 3)          2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 1, 1)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 1, 1)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 4,725\n",
      "Trainable params: 4,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data_i = Input(shape=(time_steps, grid_size_w, grid_size_h))\n",
    "conv_1 = Conv2D(16, (2, 2), activation=\"relu\", data_format=\"channels_first\")(data_i)\n",
    "conv_2 = Conv2D(32, (2, 2), activation=\"relu\", data_format=\"channels_first\")(conv_1)\n",
    "pool_1 = MaxPooling2D(data_format=\"channels_first\")(conv_2)\n",
    "drop_1 = Dropout(0.25)(pool_1)\n",
    "flat_1 = Flatten()(drop_1)\n",
    "feed_1 = Dense(64, activation=\"relu\")(flat_1)\n",
    "drop_2 = Dropout(0.25)(feed_1)\n",
    "feed_2 = Dense(n_actions, activation=\"linear\")(drop_2)\n",
    "data_o = feed_2\n",
    "\n",
    "model = Model(inputs=data_i, outputs=data_o)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Motion import Motion\n",
    "\n",
    "def tuple_to_batch(known_data):\n",
    "    batch = []\n",
    "    for i,agent_pos in enumerate(known_data[2]):\n",
    "        batch.append(np.concatenate((known_data[0],known_data[1],known_data[2][i:i+1])))\n",
    "    batch = np.array(batch)\n",
    "    return batch\n",
    "\n",
    "def valid_move_mask(batch):\n",
    "    mask = np.ones(shape=(n_agents, n_actions))\n",
    "    indices = np.array(np.nonzero(batch[:, n_channels, :, :])).T\n",
    "    for idx in indices:\n",
    "        agent, row, col = idx\n",
    "        for action in range(n_actions):\n",
    "            d_pos = Motion(action).value()\n",
    "            row += d_pos[0]\n",
    "            col += d_pos[1]\n",
    "            if row == -1 or row == grid_size_h or col == -1 or col == grid_size_w:\n",
    "                mask[agent, action] = 0\n",
    "    return mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]]]), array([[[ 1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1]]]), array([[[1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]]]))\n",
      "(1, 3, 5, 5)\n",
      "Episode 1 of 10\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for axis 1 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-312799f807c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_move_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mQ_rand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-cec3204a6c24>\u001b[0m in \u001b[0;36mvalid_move_mask\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvalid_move_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_agents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 7 is out of bounds for axis 1 with size 3"
     ]
    }
   ],
   "source": [
    "importlib.reload(E)\n",
    "\n",
    "for i in range(n_episodes):\n",
    "    env = E.Environment(dim=(grid_size_h,grid_size_w),\n",
    "                        REWARD_EAT_TRASH=10,\n",
    "                        REWARD_INVALID_MOVE=0, \n",
    "                        REWARD_NOTHING_HAPPEND=0,\n",
    "                        TRASH_APPEARENCE_PROB=0.1,\n",
    "                        NUMBER_TRASH_SOURCES=1,\n",
    "                        saved_timesteps=time_steps)\n",
    "    d = []\n",
    "    action_avg = np.zeros((400,5))\n",
    "    list_avg_rwd = []\n",
    "    list_steps = []\n",
    "\n",
    "    for k in range(n_agents):\n",
    "        env.add_agent(coord=(k,0),capacity=100000)\n",
    "    \n",
    "    print(env.export_known_data())\n",
    "    \n",
    "    X = tuple_to_batch(env.export_known_data())\n",
    "    \n",
    "    print(X.shape)\n",
    "    \n",
    "    Q_vals = model.predict(X)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(\"Episode {} of {}\".format(i + 1, n_episodes))\n",
    "\n",
    "    r_sum = 0\n",
    "    \n",
    "    for step in range(n_steps):\n",
    "        \n",
    "        mask = valid_move_mask(X)\n",
    "        if np.random.random() < epsilon:\n",
    "            Q_rand = np.random.randint(Q_vals.size()).reshape(Q_vals.shape)\n",
    "            actions = np.apply_along_axis(np.argmax, 1, Q_rand * mask).tolist()\n",
    "        else:\n",
    "            actions = np.apply_along_axis(np.argmax, 1, Q_vals * mask).tolist()\n",
    "            \n",
    "        X_reward = env.move_agents(actions) #new known state and rewards\n",
    "        # after all agents move\n",
    "        X_new = tuple_to_batch(X_reward[:3])\n",
    "        rewards = X_reward[3]\n",
    "        #print(\"Rewards {}\".format(rewards))\n",
    "        action_avg[step%400, : ] = 0\n",
    "        action_avg[step%400,actions[0]]= 1\n",
    "        d.append(rewards[0])\n",
    "        while(len(d)>400):\n",
    "            del(d[0])\n",
    "        if(step% 1000 == 0): \n",
    "            mean = sum(d) / 400.0\n",
    "            epsilon *= epsilon_decay\n",
    "            print(epsilon)\n",
    "            print(\"In Step {} the average reward of 100 is {} \".format(step, mean))\n",
    "            print(\"Actions: {}\".format(np.sum(action_avg, axis = 0)))\n",
    "            list_avg_rwd.append(mean)\n",
    "            list_steps.append(step)\n",
    "            plt.scatter(list_steps, list_avg_rwd)\n",
    "            plt.show()\n",
    "        Q_vals_new = model.predict(X_new)\n",
    "        \n",
    "        Q_vals[range(n_agents), actions] = rewards + gamma * np.max(Q_vals_new, axis=1)\n",
    "        model.fit(X, Q_vals, epochs=1, verbose=0)\n",
    "        \n",
    "        Q_vals = Q_vals_new\n",
    "        X = X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Trashbots)",
   "language": "python",
   "name": "trashbots"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
